{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AR-SSL4M Pretraining on Google Colab with Dilated Attention\n",
    "\n",
    "This notebook runs AR-SSL4M (Autoregressive Sequence Modeling for 3D Medical Image Representation) pretraining on Google Colab with **D-Former Dilated Attention** integration.\n",
    "\n",
    "## Features\n",
    "- **Dilated Attention**: Implements D-Former's dilated attention mechanism\n",
    "- **Fixed Hyperparameters**: Configurable dilated attention ratios for pretraining and finetuning\n",
    "- **Joint Training**: Supports both upstream pretraining and downstream finetuning\n",
    "- **Google Colab Optimized**: Optimized for Colab's GPU memory and runtime\n",
    "\n",
    "## Requirements\n",
    "- GPU runtime (T4, V100, or A100)\n",
    "- High RAM runtime (recommended)\n",
    "\n",
    "## Dataset\n",
    "- Using STOIC dataset (2771 samples)\n",
    "- Each sample: 128x128x128 3D medical images\n",
    "\n",
    "## Hyperparameters\n",
    "- **Pretrain Dilated Ratio**: Controls dilated attention weight in pretraining (default: 0.01)\n",
    "- **Finetune Dilated Ratio**: Controls dilated attention weight in finetuning (default: 0.01)\n",
    "- **Original Attention Ratio**: Automatically calculated as (1 - dilated_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "**Important**: If you encounter dependency conflicts, please:\n",
    "1. Restart Runtime (Runtime -> Restart Runtime)\n",
    "2. Re-run all cells\n",
    "3. If problems persist, use \"Factory Reset Runtime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base (Python 3.13.2)' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"No GPU detected! Please enable GPU runtime in Colab.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smart detection and fix PyTorch version issues\n",
    "print(\"Smart detection of Colab environment...\")\n",
    "\n",
    "# Check PyTorch version consistency\n",
    "import torch\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(f\"Detected PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Check for version inconsistencies\n",
    "result = subprocess.run([sys.executable, '-m', 'pip', 'list'], \n",
    "                       capture_output=True, text=True)\n",
    "pip_list = result.stdout\n",
    "\n",
    "torch_versions = []\n",
    "for line in pip_list.split('\\n'):\n",
    "    if line.startswith('torch ') or line.startswith('torchaudio ') or line.startswith('torchvision '):\n",
    "        torch_versions.append(line.strip())\n",
    "\n",
    "print(\"PyTorch related package versions:\")\n",
    "for version in torch_versions:\n",
    "    print(f\"  {version}\")\n",
    "\n",
    "# Force reinstall PyTorch suite to ensure consistency\n",
    "print(\"Force reinstalling PyTorch suite for consistency...\")\n",
    "\n",
    "# Uninstall existing PyTorch packages first\n",
    "%pip uninstall -y torch torchvision torchaudio\n",
    "\n",
    "# Install consistent PyTorch suite (using Colab's index)\n",
    "%pip install -q torch==2.1.0+cu121 torchvision==0.16.0+cu121 torchaudio==2.1.0+cu121 --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# Verify installation\n",
    "import torch\n",
    "print(f\"Final PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Install lightweight required packages\n",
    "print(\"Installing lightweight required packages...\")\n",
    "lightweight_packages = ['fire', 'tqdm', 'PyYAML', 'packaging']\n",
    "\n",
    "for pkg in lightweight_packages:\n",
    "    try:\n",
    "        if pkg == 'PyYAML':\n",
    "            import yaml\n",
    "            print(f\"{pkg} already available\")\n",
    "        else:\n",
    "            __import__(pkg)\n",
    "            print(f\"{pkg} already available\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {pkg}...\")\n",
    "        %pip install -q {pkg}\n",
    "\n",
    "# Check transformers (usually available in Colab)\n",
    "try:\n",
    "    import transformers\n",
    "    print(f\"Transformers: {transformers.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"Installing Transformers...\")\n",
    "    %pip install -q transformers\n",
    "\n",
    "# Finally install MONAI (if needed)\n",
    "try:\n",
    "    import monai\n",
    "    print(f\"MONAI: {monai.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"Installing MONAI (without changing PyTorch)...\")\n",
    "    %pip install -q --no-deps monai\n",
    "    # Install MONAI's required dependencies separately (avoid PyTorch version conflicts)\n",
    "    %pip install -q nibabel tqdm\n",
    "\n",
    "print(\"Smart installation completed!\")\n",
    "print(\"Strategy: Force consistent PyTorch installation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone Repository and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "import os\n",
    "repo_url = \"https://github.com/tanglehunter00/AR-SSL4M-DEMO.git\"\n",
    "\n",
    "if os.path.exists(\"AR-SSL4M-DEMO\"):\n",
    "    print(\"Repository already exists, pulling latest changes...\")\n",
    "    !cd AR-SSL4M-DEMO && git pull\n",
    "else:\n",
    "    print(\"Cloning repository...\")\n",
    "    !git clone {repo_url}\n",
    "\n",
    "# Change to project directory\n",
    "os.chdir(\"AR-SSL4M-DEMO\")\n",
    "print(f\"Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Setup\n",
    "\n",
    "Based on your screenshot, the dataset is located in Google Drive at `dataset/compressed_datasets/volumes` path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive to access your data\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set path to your data in Google Drive (based on your screenshot)\n",
    "data_path = \"/content/drive/MyDrive/dataset/compressed_datasets/volumes\"\n",
    "\n",
    "# Check if data exists\n",
    "if os.path.exists(data_path):\n",
    "    npy_files = [f for f in os.listdir(data_path) if f.endswith('.npy')]\n",
    "    print(f\"Found {len(npy_files)} .npy files in {data_path}\")\n",
    "    if len(npy_files) == 0:\n",
    "        print(\"No .npy files found in the directory\")\n",
    "        print(\"Available files:\")\n",
    "        all_files = os.listdir(data_path)[:10]  # Show first 10 files\n",
    "        for f in all_files:\n",
    "            print(f\"  - {f}\")\n",
    "else:\n",
    "    print(f\"Data path not found: {data_path}\")\n",
    "    print(\"Available paths in Google Drive:\")\n",
    "    try:\n",
    "        drive_contents = os.listdir(\"/content/drive/MyDrive\")\n",
    "        for item in drive_contents[:10]:\n",
    "            print(f\"  - /content/drive/MyDrive/{item}\")\n",
    "    except:\n",
    "        print(\"Unable to list drive contents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data list file\n",
    "import glob\n",
    "\n",
    "# Try multiple possible data paths\n",
    "possible_paths = [\n",
    "    \"/content/drive/MyDrive/dataset/compressed_datasets/volumes\",\n",
    "    \"/content/drive/MyDrive/compressed_datasets/volumes\", \n",
    "    \"/content/drive/MyDrive/dataset/volumes\",\n",
    "    \"/content/drive/MyDrive/volumes\"\n",
    "]\n",
    "\n",
    "npy_files = []\n",
    "actual_data_path = None\n",
    "\n",
    "for path in possible_paths:\n",
    "    if os.path.exists(path):\n",
    "        files = glob.glob(os.path.join(path, \"*.npy\"))\n",
    "        if files:\n",
    "            npy_files = files\n",
    "            actual_data_path = path\n",
    "            print(f\"Found {len(npy_files)} .npy files in {actual_data_path}\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Path exists but no .npy files found: {path}\")\n",
    "\n",
    "if not npy_files:\n",
    "    print(\"No .npy files found in any of the expected paths\")\n",
    "    print(\"Please check your Google Drive structure and update the paths accordingly\")\n",
    "else:\n",
    "    # Create data list file\n",
    "    data_list_path = \"pretrain/colab_data_list.txt\"\n",
    "    with open(data_list_path, 'w') as f:\n",
    "        for npy_file in npy_files:\n",
    "            f.write(f\"{npy_file}\\n\")\n",
    "    \n",
    "    print(f\"Created data list: {data_list_path} with {len(npy_files)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Configuration\n",
    "\n",
    "Configure the dilated attention hyperparameters for pretraining and finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Configuration for Dilated Attention\n",
    "print(\"Configuring Dilated Attention Hyperparameters...\")\n",
    "\n",
    "# Default hyperparameters (can be modified)\n",
    "PRETRAIN_DILATED_RATIO = 0.01  # Upstream pretraining: dilated attention weight\n",
    "FINETUNE_DILATED_RATIO = 0.01  # Downstream finetuning: dilated attention weight\n",
    "\n",
    "print(f\"Pretrain dilated attention ratio: {PRETRAIN_DILATED_RATIO}\")\n",
    "print(f\"Finetune dilated attention ratio: {FINETUNE_DILATED_RATIO}\")\n",
    "print(f\"Pretrain original attention ratio: {1 - PRETRAIN_DILATED_RATIO}\")\n",
    "print(f\"Finetune original attention ratio: {1 - FINETUNE_DILATED_RATIO}\")\n",
    "\n",
    "# You can modify these values here:\n",
    "# PRETRAIN_DILATED_RATIO = 0.05  # Example: 5% dilated, 95% original\n",
    "# FINETUNE_DILATED_RATIO = 0.1   # Example: 10% dilated, 90% original\n",
    "\n",
    "print(\"\\nTips:\")\n",
    "print(\"- Higher dilated ratio: More focus on long-range dependencies\")\n",
    "print(\"- Lower dilated ratio: More focus on local attention patterns\")\n",
    "print(\"- Recommended range: 0.01 - 0.2\")\n",
    "print(\"- You can experiment with different values for better performance\")\n",
    "\n",
    "print(\"\\nTo modify hyperparameters:\")\n",
    "print(\"1. Uncomment and change the values above\")\n",
    "print(\"2. Or modify the variables directly:\")\n",
    "print(\"   PRETRAIN_DILATED_RATIO = 0.05  # 5% dilated attention\")\n",
    "print(\"   FINETUNE_DILATED_RATIO = 0.1   # 10% dilated attention\")\n",
    "print(\"3. Re-run this cell and the training cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update dataset configuration\n",
    "config_content = '''from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class custom_dataset:\n",
    "    dataset: str = \"custom_dataset\"\n",
    "    file: str = \"image_dataset.py\"\n",
    "    train_split: str = \"train\"\n",
    "    test_split: str = \"validation\"\n",
    "    spatial_path: str = \"colab_data_list.txt\"\n",
    "    contrast_path: str = \"colab_data_list.txt\"\n",
    "    semantic_path: str = \"colab_data_list.txt\"\n",
    "    img_size = [128, 128, 128]\n",
    "    patch_size = [16, 16, 16]\n",
    "    attention_type = 'prefix'\n",
    "    add_series_data = False\n",
    "    add_spatial_data = True\n",
    "    is_subset = False\n",
    "    series_length = 4\n",
    "'''\n",
    "\n",
    "with open('pretrain/configs/datasets.py', 'w') as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "print(\"Updated dataset configuration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update training configuration for Colab with Dilated Attention\n",
    "training_config_content = f'''from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class train_config:\n",
    "    enable_fsdp: bool=False\n",
    "    low_cpu_fsdp: bool=False\n",
    "    run_validation: bool=True\n",
    "    batch_size_training: int=4  # Adjusted for Colab GPU memory\n",
    "    batching_strategy: str=\"padding\"\n",
    "    gradient_accumulation_steps: int=1\n",
    "    gradient_clipping: bool=False\n",
    "    gradient_clipping_threshold: float = 1.0\n",
    "    num_epochs: int=1  # Single epoch for Colab\n",
    "    warmup_epochs:int=0\n",
    "    num_workers_dataloader: int=0  # Set to 0 to avoid multiprocessing issues in Colab\n",
    "    lr: float=1e-4\n",
    "    weight_decay: float=0.01\n",
    "    gamma: float=0.1\n",
    "    seed: int=42\n",
    "    use_fp16: bool=True  # Enable FP16 for Colab GPU memory efficiency\n",
    "    mixed_precision: bool=True\n",
    "    val_batch_size: int=1\n",
    "    dataset = \"custom_dataset\"\n",
    "    output_dir: str=\"/content/AR-SSL4M-DEMO/pretrain/save\"\n",
    "    freeze_layers: bool=False\n",
    "    num_freeze_layers: int=1\n",
    "    save_model: bool=True\n",
    "    save_optimizer: bool=False\n",
    "    save_metrics: bool=True\n",
    "    scheduler:str='CosineLR'\n",
    "    min_lr: float=0\n",
    "    pos_type: str='sincos3d'\n",
    "    norm_pixel_loss: bool=True\n",
    "    enable_profiling: bool=False  # Disable profiling for cleaner output\n",
    "    # Dilated Attention Hyperparameters\n",
    "    pretrain_dilated_ratio: float={PRETRAIN_DILATED_RATIO}\n",
    "    finetune_dilated_ratio: float={FINETUNE_DILATED_RATIO}\n",
    "'''\n",
    "\n",
    "with open('pretrain/configs/training.py', 'w') as f:\n",
    "    f.write(training_config_content)\n",
    "\n",
    "print(\"Updated training configuration for Colab with Dilated Attention\")\n",
    "print(f\"Pretrain dilated ratio: {PRETRAIN_DILATED_RATIO}\")\n",
    "print(f\"Finetune dilated ratio: {FINETUNE_DILATED_RATIO}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Start Pretraining with Dilated Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create save directory\n",
    "os.makedirs(\"pretrain/save\", exist_ok=True)\n",
    "print(\"Created save directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start pretraining with Dilated Attention\n",
    "print(\"Starting AR-SSL4M Pretraining with Dilated Attention...\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Pretrain dilated ratio: {PRETRAIN_DILATED_RATIO}\")\n",
    "print(f\"Finetune dilated ratio: {FINETUNE_DILATED_RATIO}\")\n",
    "print(f\"Pretrain original ratio: {1 - PRETRAIN_DILATED_RATIO}\")\n",
    "print(f\"Finetune original ratio: {1 - FINETUNE_DILATED_RATIO}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Change to pretrain directory and run\n",
    "os.chdir(\"pretrain\")\n",
    "\n",
    "# Run the training script with dilated attention\n",
    "!python main.py --output_dir save --batch_size_training 4 --pretrain_dilated_ratio {PRETRAIN_DILATED_RATIO} --finetune_dilated_ratio {FINETUNE_DILATED_RATIO}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Pretraining with Dilated Attention completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Check Results and Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training results\n",
    "import os\n",
    "import glob\n",
    "\n",
    "save_dir = \"save\"\n",
    "if os.path.exists(save_dir):\n",
    "    files = os.listdir(save_dir)\n",
    "    print(f\"Files in save directory:\")\n",
    "    for file in files:\n",
    "        file_path = os.path.join(save_dir, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "            print(f\"  - {file} ({size_mb:.1f} MB)\")\n",
    "else:\n",
    "    print(\"Save directory not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the trained model\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "\n",
    "# Create a zip file with all results\n",
    "zip_path = \"/content/ar_ssl4m_pretrained_model.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "    for root, dirs, files_list in os.walk(\"save\"):\n",
    "        for file in files_list:\n",
    "            file_path = os.path.join(root, file)\n",
    "            arcname = os.path.relpath(file_path, \"save\")\n",
    "            zipf.write(file_path, arcname)\n",
    "            print(f\"Added to zip: {arcname}\")\n",
    "\n",
    "print(f\"\\nCreated zip file: {zip_path}\")\n",
    "print(\"Downloading...\")\n",
    "\n",
    "# Download the zip file\n",
    "files.download(zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training summary with Dilated Attention\n",
    "print(\"AR-SSL4M Pretraining Summary with Dilated Attention\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Dataset: STOIC ({len(npy_files) if 'npy_files' in locals() and npy_files else 'Unknown'} samples)\")\n",
    "print(f\"Data path: {actual_data_path if 'actual_data_path' in locals() and actual_data_path else 'Not found'}\")\n",
    "print(f\"Model: AR-SSL4M with Dilated Attention (91.3M parameters)\")\n",
    "print(f\"Image size: 128x128x128\")\n",
    "print(f\"Patch size: 16x16x16\")\n",
    "print(f\"Batch size: 4\")\n",
    "print(f\"Learning rate: 1e-4\")\n",
    "print(f\"Epochs: 1\")\n",
    "print(f\"Pretrain dilated ratio: {PRETRAIN_DILATED_RATIO}\")\n",
    "print(f\"Finetune dilated ratio: {FINETUNE_DILATED_RATIO}\")\n",
    "print(f\"Pretrain original ratio: {1 - PRETRAIN_DILATED_RATIO}\")\n",
    "print(f\"Finetune original ratio: {1 - FINETUNE_DILATED_RATIO}\")\n",
    "print(f\"Results saved to: save/\")\n",
    "print(f\"GitHub Repo: https://github.com/tanglehunter00/AR-SSL4M-DEMO\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Training with Dilated Attention completed successfully!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Download the model zip file\")\n",
    "print(\"2. Use the pretrained model for downstream tasks\")\n",
    "print(\"3. Fine-tune on specific medical imaging tasks (segmentation, classification, etc.)\")\n",
    "print(\"4. Experiment with different dilated attention ratios for better performance\")\n",
    "print(\"5. Try different combinations of pretrain_dilated_ratio and finetune_dilated_ratio\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
