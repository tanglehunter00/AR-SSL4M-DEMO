# å›ºå®šè¶…å‚æ•°é—¨æ§æœºåˆ¶å®ç°æ€»ç»“

## ğŸ¯ å®ç°å®Œæˆ

æ ¹æ®æ‚¨çš„è¦æ±‚ï¼Œæˆ‘å·²ç»æˆåŠŸå°†é—¨æ§æœºåˆ¶ä»**è‡ªåŠ¨å­¦ä¹ **æ”¹ä¸º**å›ºå®šè¶…å‚æ•°**çº¦æŸã€‚

## ğŸ”§ ä¸»è¦ä¿®æ”¹

### 1. **ResidualGatingç±»é‡æ„**

**ä¹‹å‰ï¼ˆè‡ªåŠ¨å­¦ä¹ ï¼‰**ï¼š
```python
self.gate_weight = nn.Parameter(torch.tensor(0.01))  # å¯å­¦ä¹ å‚æ•°
gate = self.gate_activation(self.gate_weight)  # Sigmoidæ¿€æ´»
gated_output = gate * dilated_attention + (1 - gate) * original_attention
```

**ç°åœ¨ï¼ˆå›ºå®šè¶…å‚æ•°ï¼‰**ï¼š
```python
# æ³¨å†Œä¸ºbufferï¼Œä¸å‚ä¸æ¢¯åº¦è®¡ç®—
self.register_buffer('dilated_weight', torch.tensor(self.dilated_ratio))
self.register_buffer('original_weight', torch.tensor(self.original_ratio))

# ç›´æ¥ä½¿ç”¨å›ºå®šæƒé‡
gated_output = self.dilated_weight * dilated_attention + self.original_weight * original_attention
```

### 2. **æ–°å¢è¶…å‚æ•°æ§åˆ¶**

```python
def __init__(self, hidden_size: int, task_type: str = "pretrain", 
             pretrain_dilated_ratio: float = 0.01, finetune_dilated_ratio: float = 0.01):
```

- `pretrain_dilated_ratio`: ä¸Šæ¸¸é¢„è®­ç»ƒä»»åŠ¡ä¸­è†¨èƒ€æ³¨æ„åŠ›çš„æƒé‡æ¯”ä¾‹
- `finetune_dilated_ratio`: ä¸‹æ¸¸å¾®è°ƒä»»åŠ¡ä¸­è†¨èƒ€æ³¨æ„åŠ›çš„æƒé‡æ¯”ä¾‹

### 3. **æ¨¡å‹ç±»æ›´æ–°**

æ‰€æœ‰ç›¸å…³ç±»éƒ½æ·»åŠ äº†è¶…å‚æ•°æ”¯æŒï¼š
- `Attention`
- `DecoderLayer` 
- `BaseModel`
- `ReconModel`
- ä¸‹æ¸¸åˆ†å‰²æ¨¡å‹

## ğŸ“Š éªŒè¯ç»“æœ

ä»è¿è¡Œç»“æœå¯ä»¥çœ‹åˆ°ï¼š

```
=== å›ºå®šè¶…å‚æ•°é—¨æ§æœºåˆ¶éªŒè¯ ===

1. è¶…å‚æ•°è®¾ç½®:
   ä¸Šæ¸¸é¢„è®­ç»ƒè†¨èƒ€æ³¨æ„åŠ›æƒé‡: 0.01
   ä¸Šæ¸¸é¢„è®­ç»ƒåŸå§‹æ³¨æ„åŠ›æƒé‡: 0.99
   ä¸‹æ¸¸å¾®è°ƒè†¨èƒ€æ³¨æ„åŠ›æƒé‡: 0.01
   ä¸‹æ¸¸å¾®è°ƒåŸå§‹æ³¨æ„åŠ›æƒé‡: 0.99

2. é¢„è®­ç»ƒæ¨¡å‹ï¼ˆä¸Šæ¸¸ä»»åŠ¡ï¼‰:
   è†¨èƒ€æ³¨æ„åŠ›æƒé‡: 0.010000
   åŸå§‹æ³¨æ„åŠ›æƒé‡: 0.990000
   æƒé‡æ€»å’Œ: 1.000000

3. ä¸‹æ¸¸åˆ†å‰²æ¨¡å‹ï¼ˆå¾®è°ƒä»»åŠ¡ï¼‰:
   è†¨èƒ€æ³¨æ„åŠ›æƒé‡: 0.010000
   åŸå§‹æ³¨æ„åŠ›æƒé‡: 0.990000
   æƒé‡æ€»å’Œ: 1.000000
```

## âœ… å…³é”®ç‰¹æ€§

### 1. **å›ºå®šæƒé‡**
- æƒé‡ä¸ä¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ”¹å˜
- å§‹ç»ˆä¿æŒè®¾å®šçš„æ¯”ä¾‹ï¼ˆ0.01 å’Œ 0.99ï¼‰

### 2. **ä¸å‚ä¸æ¢¯åº¦è®¡ç®—**
```
é—¨æ§æƒé‡å±æ€§:
dilated_weight.requires_grad: False
original_weight.requires_grad: False
dilated_weight.is_buffer: True
```

### 3. **æ‰€æœ‰å±‚ä¸€è‡´æ€§**
```
ç¬¬1å±‚: è†¨èƒ€æƒé‡=0.010000, åŸå§‹æƒé‡=0.990000
ç¬¬2å±‚: è†¨èƒ€æƒé‡=0.010000, åŸå§‹æƒé‡=0.990000
...
ç¬¬12å±‚: è†¨èƒ€æƒé‡=0.010000, åŸå§‹æƒé‡=0.990000
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. **é¢„è®­ç»ƒé˜¶æ®µ**
```python
model = ReconModel(
    config=config,
    task_type="pretrain",
    use_dilated=True,
    pretrain_dilated_ratio=0.01,  # è†¨èƒ€æ³¨æ„åŠ›1%
    finetune_dilated_ratio=0.01   # ä¸‹æ¸¸ä»»åŠ¡1%
)
```

### 2. **å¾®è°ƒé˜¶æ®µ**
```python
model = DilatedBaseModel(
    config=config,
    task_type="finetune",
    use_dilated=True,
    pretrain_dilated_ratio=0.01,  # ä¸Šæ¸¸ä»»åŠ¡1%
    finetune_dilated_ratio=0.01   # è†¨èƒ€æ³¨æ„åŠ›1%
)
```

### 3. **è‡ªå®šä¹‰æƒé‡æ¯”ä¾‹**
```python
# ä¸Šæ¸¸ï¼šè†¨èƒ€æ³¨æ„åŠ›5%ï¼ŒåŸå§‹æ³¨æ„åŠ›95%
# ä¸‹æ¸¸ï¼šè†¨èƒ€æ³¨æ„åŠ›10%ï¼ŒåŸå§‹æ³¨æ„åŠ›90%
model = ReconModel(
    config=config,
    task_type="pretrain",
    use_dilated=True,
    pretrain_dilated_ratio=0.05,  # 5%
    finetune_dilated_ratio=0.1   # 10%
)
```

## ğŸ¯ æ€»ç»“

ç°åœ¨æ‚¨æœ‰äº†ï¼š

1. **å®Œå…¨å›ºå®šçš„é—¨æ§æƒé‡**ï¼šä¸ä¼šè‡ªåŠ¨è°ƒæ•´
2. **ä¸¤ä¸ªç‹¬ç«‹çš„è¶…å‚æ•°**ï¼šåˆ†åˆ«æ§åˆ¶ä¸Šæ¸¸å’Œä¸‹æ¸¸ä»»åŠ¡çš„æƒé‡æ¯”ä¾‹
3. **å¼ºåˆ¶çº¦æŸ**ï¼šä¸¥æ ¼æŒ‰ç…§è®¾å®šçš„æ¯”ä¾‹è¿›è¡ŒåŠ æƒ
4. **ä¸å‚ä¸è®­ç»ƒ**ï¼šé—¨æ§æƒé‡ä¸ä¼šåœ¨åå‘ä¼ æ’­ä¸­æ›´æ–°

è¿™æ ·å°±å®Œå…¨ç¬¦åˆæ‚¨çš„è¦æ±‚ï¼š**é€šè¿‡ä¸Šæ¸¸ä¸‹æ¸¸å„ä¸€ä¸ªè¶…å‚æ¥å¼ºåˆ¶çº¦æŸ**ï¼Œè€Œä¸æ˜¯è®©æ¨¡å‹è‡ªåŠ¨å­¦ä¹ æƒé‡æ¯”ä¾‹ï¼
